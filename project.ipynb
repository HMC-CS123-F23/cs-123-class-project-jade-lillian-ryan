{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Reviewers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks for reviewing! This project is to teach ray tracing for novices. Our overall coding priority right now is to generate a final image of a dining room scene. We would appreciate feedback on how readable our code is, especially the code creating scene objects and implementing reflections. We would also like to know if you think we prpvide enough background and that the prose is clear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Update after class on Monday\n",
    "\n",
    "The outline is:\n",
    " - **Background on ray tracing** - unfinished\n",
    " - **Scene geometry construction** - unfinished\n",
    " - **Ray tracing** - unfinished\n",
    " - **Reflection modeling** - unfinished\n",
    " - **Enhancements** - unfinished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "# Ray Tracing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Team**: Jade Kessinger, Ryan Nguyen, Lillian Vernooy\n",
    "\n",
    "**Summary**: Users will be able to perform vector operations on rays that are simulating photons and render a realistic image of a dining room scene. This will provide insight into how we as programmers simplify and approximate real-life physics into something computable with finite memory and time, which is a good step into more complex concepts in computer graphics, such as simulating water, snow, fire, etc.\n",
    "\n",
    "**Audience**: Students who are familiar with Python and basic vector geometry, but haven't had much experience with computer graphics. These individuals are interested in simulating light in a virtual environment and learning about how computers render images, but not necessarily a complex graphics engine.\n",
    "\n",
    "**Libraries used**: `NumPy`, `matplotlib`\n",
    "\n",
    "**Vocabulary**: rays, vector operations, pixels, images, computer graphics, physics, virtual camera, image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: add image above once we finish the tutorial\n",
    "\n",
    "In this tutorial, we will introduce you to computer graphics by implementing a ray tracing algorithm to generate an image of a dining room scene, like the one pictured above. We will use the `Numpy` library for vector geometry and `matplotlib` to display our image.\n",
    "\n",
    "As we move through the tutorial, we will discuss:\n",
    " - What ray tracing is and how it is used in movies and video games\n",
    " - The general ray tracing algorithm in pseudocode\n",
    " - How to simulate 3D objects using classes and inheritance\n",
    " - How to create a 3D coordinate system where the scene will reside\n",
    " - How to use vector geometry to describe how light interacts with the world by creating an array of pixels\n",
    " - How a camera forms a raster image by having each pixel record light intensity\n",
    " - How to calculate the illumination of an object based on the angle between the surface and light source\n",
    " - How to determine the color of an object based on the degree of illumination\n",
    " - How to display an image with `matplotlib`\n",
    "\n",
    "You can run this notebook on Google Colab\n",
    "\n",
    "TODO: add the enhancements we choose to include\n",
    "\n",
    "TODO: add google colab link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computer Science\n",
    "This tutorial assumes knowledge introductory computer science topics such as loops, recursion, and list comprehensions in Python. We also assume object oriented programming background which we will use to model objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Algebra\n",
    "\n",
    "We'll be using basic vector geometry to model light, so it is important to know the following properties:\n",
    " - **Vector between two points**: To compute a vector between points $A$ and $B$, we subtract $B - A$ \n",
    " - **Length of a vector**: denoted $\\vert \\vert \\overrightarrow{v} \\vert \\vert$, is the square root of the sum of the squared components: for vector $\\overrightarrow{v} = \\langle a, b \\rangle$, then $\\vert \\vert \\overrightarrow{v} \\vert \\vert = \\sqrt{a^2 + b^2}$.\n",
    " - **Unit-vector**: a vector of length 1: $\\vert \\vert \\overrightarrow{u} \\vert \\vert = 1$\n",
    " - **Normalization**: divide each component of a vector by its length. This gives us a unit vector pointing in the same direction: $\\overrightarrow{u} = \\overrightarrow{v} / \\vert \\vert \\overrightarrow{v} \\vert \\vert$\n",
    " - **Dot product**: sum of the product of each component. The dot product of a vector with itself is $\\overrightarrow{v} \\cdot \\overrightarrow{v} = \\vert \\vert \\overrightarrow{v} \\vert \\vert^2$\n",
    " - **Solving a quadratic equation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Physics\n",
    "\n",
    "We will be modeling rays of light and their intersection with objects. We only expect a very basic understanding of light which is usually covered in high-school physics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Ray Tracing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ray tracing* **simulates paths of light** as they **intersect with objects** to render highly-realistic images from scratch. More optimized versions of this ray tracing algorithm are used in many CGI movies and modern video games, such as *Stray* pictured below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![picture](https://drive.google.com/uc?export=view&id=12zeBJrD0HrQpjoXe5iPn4xZ4qmL2hUVV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the reflections of light in the puddles and textures of the scene objects? Running the game quickly with these highly-realistic visuals is possible because of ray tracing! As you complete this tutorial, you'll be one step closer to creating visuals like these. Neat!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Scene Geometry Construction\n",
    "\n",
    "TODO: Remove this text once we have finished the section\n",
    "\n",
    "Next, we must construct the geometry that we will render. In order to apply ray tracing to the geometry, every object or surface in the scene must be described by a function, so that the intersection (if it exists) of a casted ray can be calculated with each element in the scene. For an arbitrary geometry, this could quickly become complicated, so it will be desirable to create a small set of functions to describe simple geometric primitives, and then to build our scene geometry out of these.\n",
    "\n",
    "Tasks:\n",
    "\n",
    "- Write a set of generic functions to describe the surfaces of some set of geometric objects.\n",
    "- Create a 3D coordinate system in which the scene will reside. - done\n",
    "- Build up the scene by using our set of functions to describe actual objects in the space. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the scene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this ray tracing algorithm, we need to set up a **scene** with the following components:\n",
    " - **3D space**: a three coordinate graph, which we'll store in an array\n",
    " - **Objects**: Spheres, Cubes, etc. to simulate the dining table, chairs, walls, and plant.\n",
    " - **Light source**: One position where light will emit from\n",
    " - **Camera**: One position to observe the scene\n",
    " - **Screen**: A rectangle where the camera is looking through to observe the objects\n",
    "\n",
    "TODO: Insert visual of these objects (we probably want to make our own)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating our 3D Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start coding, let's import our required libraries.\n",
    "\n",
    "The `NumPy` will help us perform vector geometry on arrays. In this tutorial, we'll be using many `NumPy` arrays, which you can think of as lists of lists in Python. `NumPy` will provide us with useful functions to manipulate those arrays efficiently.\n",
    "\n",
    "`matplotlib`, specifically `matplotlib.pyplot`, is often used to produce plots and figures in Python. In this tutorial, we'll use it to display our image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start creating our scene. First we can decide how big our scene is by creating `height` and `width` variables.  For now, we'll create a scene of 300x200 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 300\n",
    "height = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can create our `image`, which will be a three dimensional `NumPy` array with the x-axis as height and the y-axis as width. Our z-axis only needs to consist of 3 points for just our camera, the screen, and the objects.\n",
    "\n",
    "To create this array, we'll use `np.zeros`. This function takes in a *shape* (an int or a tuple of ints) and creates a `NumPy` array of the given shape filled with zeros. You can read the documentation [here](https://numpy.org/doc/stable/reference/generated/numpy.zeros.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.zeros((height, width, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create our camera. To make things simple, we'll put it at (x=0, y=0, and z=-1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = np.array([0,0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can choose the amount of space we want our screen to occupy. Since our objects, camera, and screen size are relative to each other, we can make things easier for ourselves by making our screen width from x=-1 to x=1. It's important, however, to maintain the correct aspect ratio of our screen size, so we'll have to set our screen height to range from y=1/(width/height) and y=-1/(width/height) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = width / height\n",
    "screen = (-1, 1 / ratio, 1, -1 / ratio) # left, top, right, bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that we have things set up correctly, let's try displaying the image. We can use `plt.imshow` which takes in an array and displays it as an image. We'll also turn off our axis since we're only concerned with viewing the image, not a plot, using `plt.axis(\"off\")`. We'll still have a small white border."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11b463850>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.axis(\"off\")\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! This gives us what we'd expect so far, which is just a black image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a scene, we'll need to define objects. We can keep our objects stored in a list. Since we haven't implemented any objects yet, this list will be empty for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each object stored in this list, we'll want to associate a `type` with it (such as \"plane\", \"sphere\", etc.) and the `position` of the object as a coordinate in our 3D space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a plane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll add a floor to our image by defining a plane. We'll position our plane on the ground of our screen at (x=0, y=1, z=0). The conventional way to define a plane in computer graphics is to store a point on the plane and the vector normal to its surface. We choose y = 1 because our y-axis is flipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects.append({'type': 'plane', 'position': np.array([0.0, 1.0, 0.0]), 'normal':np.array([0.0, 1.0, 0.0])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll need a function to say when a ray with an associated *ray_origin* and *ray_direction* intersects with our plane at a given *position*. \n",
    "\n",
    "We compute the distance of the ray and intersection point using the formula for line-plane intersection (https://en.wikipedia.org/wiki/Line%E2%80%93plane_intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plane_intersect(position, normal, ray_origin, ray_direction):\n",
    "    denom = np.dot(ray_direction, normal)\n",
    "    if np.abs(denom) < 1e-6:\n",
    "        return None\n",
    "    dist = np.dot(ray_origin - position, normal) / denom\n",
    "    if dist < 0:\n",
    "        return None\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a Sphere\n",
    "\n",
    "We can also define a sphere\n",
    "\n",
    "TODO: Decide if we want to keep the spheres (I'll add the full explanation if we are)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sphere_intersect(center, radius, ray_origin, ray_direction):\n",
    "    b = 2 * np.dot(ray_direction, ray_origin - center)\n",
    "    c = np.linalg.norm(ray_origin - center) ** 2 - radius ** 2\n",
    "    delta = b ** 2 - 4 * c\n",
    "    if delta > 0:\n",
    "        t1 = (-b + np.sqrt(delta)) / 2\n",
    "        t2 = (-b - np.sqrt(delta)) / 2\n",
    "        if t1 > 0 and t2 > 0:\n",
    "            return min(t1, t2)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a Cuboid\n",
    "\n",
    "We also need to create cuboids for our table and chairs. To do this, we'll be creating 2 triangles for each side of the cuboid, meaning we'll have 12 triangles total.\n",
    "\n",
    "TODO: Finish text after implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# does not work :(\n",
    "def box_intersect(min, max, ray_origin, ray_direction):\n",
    "    tmin = (min[0] - ray_origin[0]) / ray_direction[0]\n",
    "    tmax = (max[0] - ray_origin[0]) / ray_direction[0]\n",
    "    tymin = (min[1] - ray_origin[1]) / ray_direction[1]\n",
    "    tymax = (max[1] - ray_origin[1]) / ray_direction[1]\n",
    "\n",
    "    if (tmin > tymax) or (tymin > tmax):\n",
    "        return None\n",
    "    \n",
    "    if (tymin > tmin):\n",
    "        tmin = tymin\n",
    "    if (tymax < tmax):\n",
    "        tmax = tymax\n",
    "\n",
    "    tzmin = (min[2] - ray_origin[2]) / ray_direction[2]\n",
    "    tzmax = (max[2] - ray_origin[2]) / ray_direction[2]\n",
    "\n",
    "    if (tmin > tzmax) or (tzmin > tmax):\n",
    "        return None\n",
    "\n",
    "    if tzmin > tmin:\n",
    "        tmin = tzmin\n",
    "    if tzmax < tmax:\n",
    "        tmax = tzmax\n",
    "\n",
    "    return tmin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a ray\n",
    "\n",
    "To define a ray that will start at the *camera* and go to a specific *pixel*, we can define a unit-vector that points in the direction of the camera to the pixel. To get this vector, we can normalize the `pixel - camera` vector.\n",
    "\n",
    "Many of our functions will require normalized vectors, so let's implement a `normalize` function using `np.linalg.norm`, which when given a vector returns the length of the vector (aka the vector norm). You can read the documentation [here](https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(vector):\n",
    "    return vector / np.linalg.norm(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions calculate the vector representing when a ray bounces from an object, compute the distance of the intersection point to the ray's origin, find the normal vector to the object's surface from the ray, and determine what the nearest object is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reflected(vector, axis):\n",
    "    return vector - 2 * np.dot(vector, axis) * axis\n",
    "\n",
    "def get_distance(obj, ray_origin, ray_direction):\n",
    "    if obj['type'] == 'plane':\n",
    "        return plane_intersect(obj['position'], obj['normal'], ray_origin, ray_direction)\n",
    "    elif obj['type'] == 'sphere':\n",
    "        return sphere_intersect(obj['center'], obj['radius'], ray_origin, ray_direction)\n",
    "    elif obj['type'] == 'box':\n",
    "        return box_intersect(obj['min'], obj['max'], ray_origin, ray_direction)\n",
    "\n",
    "def get_normal_to_surface(obj, intersection):\n",
    "    if obj['type'] == 'plane':\n",
    "        return normalize(obj['normal'])\n",
    "    elif obj['type'] == 'sphere' or obj['type'] == 'box':\n",
    "        return normalize(intersection - obj['center'])\n",
    "    \n",
    "def nearest_intersected_object(objects, ray_origin, ray_direction):\n",
    "    distances = [get_distance(obj, ray_origin, ray_direction) for obj in objects]\n",
    "    nearest_object = None\n",
    "    min_distance = np.inf\n",
    "    for index, distance in enumerate(distances):\n",
    "        if distance and distance < min_distance:\n",
    "            min_distance = distance\n",
    "            nearest_object = objects[index]\n",
    "    return nearest_object, min_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up an image with a resolution of 300x200 pixels although this can be changed if the user wants a higher resolution image at the cost of the program taking longer to run. We also set up the scene with a camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating image and scene\n",
    "width = 300\n",
    "height = 200\n",
    "\n",
    "max_depth = 3\n",
    "\n",
    "camera = np.array([0, 0, 1])\n",
    "ratio = float(width) / height\n",
    "screen = (-1, 1 / ratio, 1, -1 / ratio) # left, top, right, bottom\n",
    "\n",
    "light = { 'position': np.array([5, 5, 5]), 'ambient': np.array([1, 1, 1]), 'diffuse': np.array([1, 1, 1]), 'specular': np.array([1, 1, 1]) }\n",
    "\n",
    "image = np.zeros((height, width, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize the objects that exist in the scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remove this overall declaration and put each object with their definition\n",
    "# (append every new object to an ongoing objects list as we move through the tutorial)\n",
    "\n",
    "# Creating objects\n",
    "objects = [\n",
    "    {'type': 'sphere', 'center': np.array([-0.2, 0, -1]), 'radius': 0.7, 'ambient': np.array([0.1, 0, 0]), 'diffuse': np.array([0.7, 0, 0]), 'specular': np.array([1, 1, 1]), 'shininess': 100, 'reflection': 0.5 },\n",
    "    {'type': 'sphere', 'center': np.array([0.1, -0.3, 0]), 'radius': 0.1, 'ambient': np.array([0.1, 0, 0.1]), 'diffuse': np.array([0.7, 0, 0.7]), 'specular': np.array([1, 1, 1]), 'shininess': 100, 'reflection': 0.5 },\n",
    "    {'type': 'sphere', 'center': np.array([-0.3, 0, 0]), 'radius': 0.15, 'ambient': np.array([0, 0.1, 0]), 'diffuse': np.array([0, 0.6, 0]), 'specular': np.array([1, 1, 1]), 'shininess': 100, 'reflection': 0.5 },\n",
    "    # left\n",
    "    # {'type': 'plane', 'position': np.array([1.1, 0.0, 0.0]), 'normal': np.array([1.0, 0.0, 0.0]), 'ambient': np.array([0.65, 0.05, 0.05]), 'diffuse': np.array([0.6, 0.6, 0.6]), 'specular': np.array([0, 0, 0]), 'shininess': 0, 'reflection': 0.0},\n",
    "    # # right\n",
    "    # {'type': 'plane', 'position': np.array([-1.1, 0.0, 0.0]), 'normal': np.array([-1.0, 0.0, 0.0]), 'ambient': np.array([0.12, 0.45, 0.15]), 'diffuse': np.array([0.6, 0.6, 0.6]), 'specular': np.array([0, 0, 0]), 'shininess': 0, 'reflection': 0.0},\n",
    "    # # bottom\n",
    "    {'type': 'plane', 'position': np.array([0.0, 1.0, 0.0]), 'normal': np.array([0.0, 1.0, 0.0]), 'ambient': np.array([0.5, 0.5, 0.5]), 'diffuse': np.array([0.6, 0.6, 0.6]), 'specular': np.array([0, 0, 0]), 'shininess': 0, 'reflection': 0.0},\n",
    "    # # top\n",
    "    # {'type': 'plane', 'position': np.array([0.0, -1.0, 0.0]), 'normal': np.array([0.0, -1.0, 0.0]), 'ambient': np.array([0.93, 0.93, 0.93]), 'diffuse': np.array([0.6, 0.6, 0.6]), 'specular': np.array([0, 0, 0]), 'shininess': 0, 'reflection': 0.0},\n",
    "    # # far\n",
    "    # {'type': 'plane', 'position': np.array([0.0, 0.0, 4.0]), 'normal': np.array([0.0, 0.0, 1.0]), 'ambient': np.array([0.93, 0.93, 0.93]), 'diffuse': np.array([0.6, 0.6, 0.6]), 'specular': np.array([0, 0, 0]), 'shininess': 0, 'reflection': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Ray Tracing\n",
    "\n",
    "Our third task will be to implement the actual ray tracing operation, in which rays are cast outwards to determine where objects will appear in the image. First, we will decide on a point in space to be the camera position, and define a rectangle to be the focal plane. Then, we create an array to represent the image, and map each pixel to a location on the focal plane. Finally, we can determine which object in the scene each pixel in the camera will display, by casting a ray out from the camera through a given pixel in the focal plane, and then recording which object (and the corresponding point in space) that the ray impacts first.\n",
    "\n",
    "Tasks:\n",
    "\n",
    "- Define the camera and focal plane positions.\n",
    "- Create an array to represent the image, and determine the location of each pixel on the focal plane.\n",
    "- Cast a ray from the camera position through each pixel in the focal plane, and determine the nearest object that each ray intersects (and the intersection point)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To divide our screen into pixels evenly, we'll use `np.linspace`. `np.linspace` will create a `NumPy` array of *num* evenly spaced samples, calculated over the interval [*start*, *stop*] (inclusive). You can read the documentation [here](https://numpy.org/doc/stable/reference/generated/numpy.linspace.html).\n",
    "\n",
    "With `np.linspace`, we can evenly divide the height of our screen by the height of our image and the width of our screen by the width of our image. Then, we can traverse these arrays to get the y and x values of our pixels.\n",
    "\n",
    "TODO: explain enumerate\n",
    "we'll need to We'll also be using the built-in function `enumerate`, which takes in a list or array and returns the same list or array with a counter for each element."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: refactor code for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO! Not working code (outputs black image)\n",
    "image = np.zeros((height, width, 3))\n",
    "for i, y in enumerate(np.linspace(screen[1], screen[3], height)):\n",
    "    for j, x in enumerate(np.linspace(screen[0], screen[2], width)):\n",
    "        # screen is on origin\n",
    "        pixel = np.array([x, y, 0])\n",
    "        origin = camera\n",
    "        direction = normalize(pixel - origin)\n",
    "\n",
    "        color = np.zeros((3))\n",
    "        reflection = 1\n",
    "\n",
    "        for k in range(max_depth):\n",
    "            # check for intersections\n",
    "            nearest_object, min_distance = nearest_intersected_object(objects, origin, direction)\n",
    "            if nearest_object is None:\n",
    "                break\n",
    "\n",
    "            intersection = origin + min_distance * direction\n",
    "            normal_to_surface = get_normal_to_surface(nearest_object, intersection)\n",
    "            shifted_point = intersection + 1e-5 * normal_to_surface\n",
    "            intersection_to_light = normalize(light['position'] - shifted_point)\n",
    "\n",
    "            _, min_distance = nearest_intersected_object(objects, shifted_point, intersection_to_light)\n",
    "            intersection_to_light_distance = np.linalg.norm(light['position'] - intersection)\n",
    "            is_shadowed = min_distance < intersection_to_light_distance\n",
    "\n",
    "            if is_shadowed:\n",
    "                break\n",
    "\n",
    "            illumination = np.zeros((3))\n",
    "\n",
    "            # ambiant\n",
    "            illumination += nearest_object['ambient'] * light['ambient']\n",
    "\n",
    "            # diffuse\n",
    "            illumination += nearest_object['diffuse'] * light['diffuse'] * np.dot(intersection_to_light, normal_to_surface)\n",
    "\n",
    "            # specular\n",
    "            intersection_to_camera = normalize(camera - intersection)\n",
    "            H = normalize(intersection_to_light + intersection_to_camera)\n",
    "            illumination += nearest_object['specular'] * light['specular'] * np.dot(normal_to_surface, H) ** (nearest_object['shininess'] / 4)\n",
    "\n",
    "            # reflection\n",
    "            color += reflection * illumination\n",
    "            reflection *= nearest_object['reflection']\n",
    "\n",
    "            origin = shifted_point\n",
    "            direction = reflected(direction, normal_to_surface)\n",
    "\n",
    "        image[i, j] = np.clip(color, 0, 1)\n",
    "    print(\"%d/%d\" % (i + 1, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Image to output\n",
    "plt.imsave('image.png', image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Reflection Modeling\n",
    "\n",
    "Next, we must determine the actual color to assign to each pixel. The first step in this process is to cast a ray from the point of intersection at the object to the light source, in order to determine if the object is shadowed by any other objects. We can then determine the illumination of the point. In the interest of beginning with the simplest possible system, we can begin with a simple diffuse reflection model in which light from the source is scattered in all directions. In this case, the illumination of a point on an object can be calculated based on the angle between the surface normal at that point and the ray which runs from the point to the light source — the cosine of the angle will give us the illumination of the point. The color of the object can also be incorporated at this point. Once we complete this step, we should be able to create a basic rendering of the scene.\n",
    "\n",
    "Tasks:\n",
    "\n",
    "- Cast rays to determine whether a given point is in shadow.\n",
    "- Calculate illumination based on angle between surface and light source.\n",
    "- Determine final pixel color by combining degree of illumination and color of object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Enhancements\n",
    "\n",
    "Once we have created a basic rendering of the scene, we will add enhancements that will improve the photorealism of the scene. Some possibilities are listed below.\n",
    "\n",
    "Tasks:\n",
    "\n",
    "- Implement the Phong reflection model to shade objects more accurately by including specular, diffuse, and ambient components.\n",
    "- Adding multiple bounces in order to render reflections.\n",
    "- Implement refraction for transparent/translucent objects.\n",
    "- Implement textures by varying shading parameters across the surface of an object.\n",
    "- (If time allows) More complicated geometries. For example, import an STL file, and parse it to determine the set of triangular surfaces in 3D space that it represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "References\n",
    "\n",
    "[1] https://numpy.org/doc/stable/reference/generated/numpy.zeros.html\n",
    "\n",
    "[2] https://numpy.org/doc/stable/reference/generated/numpy.linspace.html\n",
    "\n",
    "[3] https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html\n",
    "\n",
    "TODO: add/complete references"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
